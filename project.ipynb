{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT DATA MINING- AIRBNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link of Database :https://www.kaggle.com/brittabettendorf/berlin-airbnb-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "## Determine Business Objectives\n",
    "### Background \n",
    "\n",
    "In this project, we are a private individual who owns an apartment located in the city of Berlin and we often go on trips and we want to be able to make the purchase of the house profitable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Objectives \n",
    "\n",
    "The objective of our business is to rent our Berlin apartments using airBNB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Success criteria\n",
    "\n",
    "Success will depend on finding a price and frequency of visits that will maximize our profits when we leave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess situation \n",
    "### Inventory of ressources \n",
    "\n",
    "we have an apartment of 2 bedrooms, 4 beds, 1 bathroom, wifi, kitchen, microwave oven,3 accomodates, distance of center 3.52234\n",
    "amenities = 5\n",
    "requires_license = 1\n",
    "instant_bookable = 1\n",
    "guests_included = 1\n",
    "extra_people = 10\n",
    "require_guest_phone_verification = 0\n",
    "bathrooms = 1\n",
    "bedrooms = 2\n",
    "beds = 4\n",
    "accomodates = 3\n",
    "host_total_listings_count = 4\n",
    "host_has_profile_pic  = 1\n",
    "host_identity_verified = 1\n",
    "is_location_exact = 1\n",
    "host_is_superhost = 1\n",
    "minimum_nights = 2\n",
    "cancellation = \"cancellation_policy_moderate\"\n",
    "bed_type = \"bed_type_Real Bed\"\n",
    "property_type = \"property_type_Apartment\"\n",
    "room_type = \"room_type_Entire home/apt\"\n",
    "distance =3.52234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements Assumptions & constraints\n",
    "it will be assumed that the individual cannot rent his house all year round. he lives in it, so we will have to try to maximize the period when he will be able to rent his apartment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk and Contingencies \n",
    "\n",
    "The risks are to make our apartment too expensive and therefore not to rent it. There is also the price of real property which often moves so it is necessary to know how to adapt (for example since the crisis of covid-19, there is a strong chance that the price of an airbnb are less expensive so using the data before covid is less interesting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costs and Benefits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Data Mining Goals\n",
    "### Data Mining Goals\n",
    "\n",
    "The objective of Data Mining is to propose a rental price of the apartment per month in order to be almost sure that it will be rented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Mining Success Criteria\n",
    "\n",
    "Success will be measured by the margin of error between the prediction of the price and its true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce Project Plan  \n",
    "### Project plan \n",
    "\n",
    "* Data Understanding\n",
    "    * collect intial Data\n",
    "    * Describe Data \n",
    "        * Data Description Report  \n",
    "        * listing\n",
    "    * Explore Data \n",
    "        * Data Exploration Report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Assessment of tools, and techniques\n",
    "\n",
    "We are going to use a SVM that will predict the price we should put for our apartment based on the data we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect initial Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7eb107b6ba1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'seaborn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgreat_circle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "from geopy.distance import great_circle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to help us in our analysis we have 6 databases on Airbnb:\n",
    "* calendar_summary.csv\n",
    "* listings.csv\n",
    "* listings_summary.csv\n",
    "* neighbourhoods.csv\n",
    "* review.csv\n",
    "* reviews_summary.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Data \n",
    "### Data Description Report  \n",
    "#### listing\n",
    "\n",
    "\n",
    "This database contains the first information that can be found for each possible reservation proposal.\n",
    "\n",
    "This database is a part of the listing_summary database. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset listing has 22552 rows and 16 columns.\n",
      "columns of database: Index(['id', 'name', 'host_id', 'host_name', 'neighbourhood_group',\n",
      "       'neighbourhood', 'latitude', 'longitude', 'room_type', 'price',\n",
      "       'minimum_nights', 'number_of_reviews', 'last_review',\n",
      "       'reviews_per_month', 'calculated_host_listings_count',\n",
      "       'availability_365'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read \n",
    "listing = pd.read_csv(\"./data/listings.csv\", delimiter = ',')\n",
    "# checking shape\n",
    "print(\"The dataset listing has {} rows and {} columns.\".format(*listing.shape))\n",
    "\n",
    "# check the columns we currently have\n",
    "print(\"columns of database: {}\".format(listing.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### listing_summary \n",
    "\n",
    "\n",
    "\n",
    "In this database you will find all the information related to the booking proposal. \n",
    "\n",
    "Each id represents a possible reservation with all its information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_summary = pd.read_csv(\"./data/listings_summary.csv\", delimiter = ',')\n",
    "# checking shape\n",
    "print(\"The dataset listing_summary has {} rows and {} columns.\".format(*listing_summary.shape))\n",
    "\n",
    "# check the columns we currently have\n",
    "print(\"columns of database: {}\".format(listing_summary.columns))\n",
    "listing_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an enormous amount of information that is not useful to us and therefore will be removed in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calendar_summary\n",
    "Each line represents a reservation with a date, the availability of the property and the rental price at that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_summary = pd.read_csv(\"./data/calendar_summary.csv\", delimiter = ',')\n",
    "# checking shape\n",
    "print(\"The dataset calendar_summary has {} rows and {} columns.\".format(*calendar_summary.shape))\n",
    "\n",
    "# check the columns we currently have\n",
    "calendar_summary.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### neighbourhoods\n",
    "\n",
    "\n",
    "\n",
    "This database contains all the districts and neighbourhoods that make up Berlin, the neighbourhood information of each reservation is given in the variables 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed' of the listing_summary database, so it will not be necessary to keep this neighbourhoods database for the next analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhoods  = pd.read_csv(\"./data/neighbourhoods.csv\", delimiter = ',')\n",
    "# checking shape\n",
    "print(\"The dataset neighbourhoods has {} rows and {} columns.\".format(*neighbourhoods.shape))\n",
    "\n",
    "# check the columns we currently have\n",
    "print(\"columns of database: {}\".format(neighbourhoods.columns))\n",
    "neighbourhoods.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews\n",
    "\n",
    "\n",
    "This database contains all the comments put for each reservation according to the day.\n",
    "\n",
    "By finding the period of the stays or in any case the average, with the average of the comments per month, we can conjecture on the number of days booked per month for a reservation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"./data/reviews.csv\", delimiter = ',')\n",
    "# checking shape\n",
    "print(\"The dataset reviews has {} rows and {} columns.\".format(*reviews.shape))\n",
    "\n",
    "# check the columns we currently have\n",
    "print(\"columns of database: {}\".format(reviews.columns))\n",
    "reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviews_summary\n",
    "\n",
    "This database contains the same information as reviews by adding reviewer_id, reviewer_name, comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_summary = pd.read_csv(\"./data/reviews_summary.csv\", delimiter = ',')\n",
    "# checking shape\n",
    "print(\"The dataset reviews_summary has {} rows and {} columns.\".format(*reviews_summary.shape))\n",
    "\n",
    "# check the columns we currently have\n",
    "print(\"columns of database: {}\".format(reviews_summary.columns))\n",
    "reviews_summary.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would surely be beneficial to analyze the comments to know the criteria that satisfy the customers, but we base ourselves on the example of an individual who has just arrived, so he has no comments and no marks on his accommodation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data \n",
    "### Data Exploration Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### work on listing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A price feature can be found in listing_summary and in calendar_summary.\n",
    "\n",
    "In listing_summary price is a data set for each reservation.\n",
    "\n",
    "In calendar_summary, it represents the price of the reservation per day when the reservation is available.\n",
    "\n",
    "Let's test the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# différence entre price dans calendar_summary et price dans listing_summary\n",
    "calendar_t = calendar_summary[calendar_summary.available ==\"t\"]\n",
    "calendar_ttt = calendar_t[calendar_t.listing_id == 2015]\n",
    "cl_price = calendar_ttt.price.str.replace('$', '').str.replace(',', '').astype(float).astype(int)\n",
    "cl_price.mean()\n",
    "cl = calendar_summary[calendar_summary.listing_id == 2015]\n",
    "print(\"mean of price {}  for {} days on {} days\".format(cl_price.mean(), cl_price.count(), cl.available.count()))\n",
    "print(\" price of {} proposed in listing_summary\".format(listing_summary[listing_summary.id == 2015].price.values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the 2 can be explained, if the price of 60$ represents what the owner receives from Airbnb. or there is missing information in calendary_summary.\n",
    "\n",
    "We could use calendar_summary to set a price for each reservation per month, which might be more useful to give a more accurate price of the apartment according to the months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "results = Counter()\n",
    "listing_summary['amenities'].str.strip('{}')\\\n",
    "               .str.replace('\"', '')\\\n",
    "               .str.lstrip('\\\"')\\\n",
    "               .str.rstrip('\\\"')\\\n",
    "               .str.split(',')\\\n",
    "               .apply(results.update)\n",
    "\n",
    "results.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe\n",
    "sub_df = pd.DataFrame(results.most_common(50), columns=['amenity', 'count'])\n",
    "\n",
    "# plot the Top 50\n",
    "sub_df.sort_values(by=['count'], ascending=True).plot(kind='barh', x='amenity', y='count',  \n",
    "                                                      figsize=(10,7), legend=False, color='darkgrey',\n",
    "                                                      title='Amenities')\n",
    "plt.xlabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### work on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data by date\n",
    "reviews.date = pd.to_datetime(reviews.date, format=\"%Y-%m-%d\")\n",
    "\n",
    "count_2018 = reviews[reviews[\"date\"].isin(pd.date_range('2018-01-01', '2018-10-31'))]\n",
    "count_2017 = reviews[reviews[\"date\"].isin(pd.date_range('2017-01-01', '2017-12-31'))]\n",
    "count_2016 = reviews[reviews[\"date\"].isin(pd.date_range('2016-01-01', '2016-12-31'))]\n",
    "count_2015 = reviews[reviews[\"date\"].isin(pd.date_range('2015-01-01', '2015-12-31'))]\n",
    "\n",
    "count_2018.loc[:,'review_count'] = 1\n",
    "count_2017.loc[:,'review_count'] = 1\n",
    "count_2016.loc[:,'review_count'] = 1\n",
    "count_2015.loc[:,'review_count'] = 1\n",
    "\n",
    "count_2018_monthly = count_2018.groupby([count_2018.date.dt.to_period(\"M\"), 'listing_id'])['review_count'].agg({'review_count':{'reviews_per_month_18':'count'}}).reset_index()\n",
    "count_2017_monthly = count_2017.groupby([count_2017.date.dt.to_period(\"M\"), 'listing_id'])['review_count'].agg({'review_count':{'reviews_per_month_17':'count'}}).reset_index()\n",
    "count_2016_monthly = count_2016.groupby([count_2016.date.dt.to_period(\"M\"), 'listing_id'])['review_count'].agg({'review_count':{'reviews_per_month_16':'count'}}).reset_index()\n",
    "count_2015_monthly = count_2015.groupby([count_2015.date.dt.to_period(\"M\"), 'listing_id'])['review_count'].agg({'review_count':{'reviews_per_month_15':'count'}}).reset_index()\n",
    "\n",
    "\n",
    "count_2018_monthly.columns = ['date', 'listing_id', 'reviews_per_month_18']\n",
    "count_2017_monthly.columns = ['date', 'listing_id', 'reviews_per_month_17']\n",
    "count_2016_monthly.columns = ['date', 'listing_id', 'reviews_per_month_16']\n",
    "count_2015_monthly.columns = ['date', 'listing_id', 'reviews_per_month_15']\n",
    "\n",
    "count_2018_monthly.set_index('date', inplace=True)\n",
    "count_2017_monthly.set_index('date', inplace=True)\n",
    "count_2016_monthly.set_index('date', inplace=True)\n",
    "count_2015_monthly.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_2018.groupby([count_2018.date.dt.to_period(\"M\"), 'listing_id'])['review_count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"dark\")\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12,10))\n",
    "\n",
    "sub_1 = count_2018_monthly.groupby('date')['reviews_per_month_18'].mean()\n",
    "sub_1.plot(ax=axes[0], color='midnightblue', style=':')\n",
    "axes[0].set_title('2018', fontweight='bold')\n",
    "axes[0].set_xlabel('') \n",
    "\n",
    "sub_2 = count_2017_monthly.groupby('date')['reviews_per_month_17'].mean()\n",
    "sub_2.plot(ax=axes[1], color='grey', style=':')\n",
    "axes[1].set_title('2017', fontweight='bold')\n",
    "axes[1].set_xlabel('') \n",
    "\n",
    "sub_3 = count_2016_monthly.groupby('date')['reviews_per_month_16'].mean()\n",
    "sub_3.plot(ax=axes[2], color='coral', style=':')\n",
    "axes[2].set_title('2016', fontweight='bold')\n",
    "axes[2].set_xlabel('') \n",
    "\n",
    "sub_4 = count_2015_monthly.groupby('date')['reviews_per_month_15'].mean()\n",
    "sub_4.plot(ax=axes[3], color='forestgreen', style=':')\n",
    "axes[3].set_title('2015', fontweight='bold')\n",
    "axes[3].set_xlabel('') \n",
    "\n",
    "# adjust space between subplots and set a title\n",
    "plt.subplots_adjust(hspace = 0.6)\n",
    "plt.suptitle('\\nAverage Reviews per Month for Berlin\\n', fontweight='bold')\n",
    "\n",
    "# plot common y-label\n",
    "fig.text(0.04, 0.5, 'Average Reviews per Month', fontweight='bold', va='center', rotation='vertical');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are more people during the April-October period and that it is in January that we have the least number of people.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have precise data on the length of stay for each review \n",
    "\n",
    "Starting from the Postula that the average stay is 3.5 days.\n",
    "\n",
    "with this information, we can guess on the number of days a reservation is rented and know the monthly income of each rental. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Data Quality \n",
    "### Data Quality Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each database we will check the percentage of missing data for each feature.\n",
    "\n",
    "so we can know which feature is usable for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value NaN in database \n",
    "def print_nan_database(database):\n",
    "    NanCol = []\n",
    "    for x in database.columns.values:\n",
    "        if database[x].isna().sum()>0:\n",
    "            NanCol.append((x, \"pourcentage : {}\".format(round(database[x].isna().sum()/database.shape[0]*100, 2))))\n",
    "\n",
    "    print(\"Features that contain nulls;  \\n\\n\")\n",
    "\n",
    "    for x in NanCol:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### working listing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nan_database(listing_summary)\n",
    "# ... and duplicates\n",
    "print(\"\\nIt contains {} duplicates.\".format(listing_summary.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be able to remove all attributes whose nan percentage is higher than 40% in this case: 'neighborhood_overview', 'notes', 'transit', 'access', 'interaction', 'house_rules', 'thumbnail_url', 'medium_url', 'xl_picture_url', 'host_acceptance_rate', 'square_feet','host_acceptance_rate', 'square_feet', 'weekly_price', 'monthly_price', 'security_deposit', 'license', 'jurisdiction_names' ne seront pas utilisé "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also remove reviews_per_months because we already have this data in the review database, moreover our model must be based on the example of a newcomer to the site, so it can not influence its reviews_for_months nor its score for the moment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# value NaN in database \n",
    "print_nan_database(reviews)\n",
    "# ... and duplicates\n",
    "print(\"\\nIt contains {} duplicates.\".format(reviews.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value NaN in database \n",
    "print_nan_database(calendar_summary)\n",
    "\n",
    "# ... and duplicates\n",
    "print(\"\\nIt contains {} duplicates.\".format(calendar_summary.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lack of value in the price column can be explained by the fact that the apartments are not available all year round, so there are days when the apartment is not available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_summary.groupby(['listing_id'])[['price']]\n",
    "\n",
    "#delete available\n",
    "calendar_summary.drop(['available'], axis = 'columns', inplace = True)\n",
    "# delete Nan \n",
    "calendar_summary.dropna(subset=['price'], inplace=True)\n",
    "print(\"\\nIt contains {} NaN.\".format(calendar_summary.price.isna().sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_summary.groupby(['listing_id'])[['price']].count().shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of lines indicates that the number of reservations for which we have a price is 11764.\n",
    "\n",
    "This is only 50% of the number of bookings in the listing_summary database.\n",
    "\n",
    "It seems therefore not possible to use this database to form a price per month for each reservation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation \n",
    "## select Data \n",
    "### Rationale for inclusion\n",
    "\n",
    "\n",
    "for the project,\n",
    "\n",
    "To analyze the relationship between the characteristics of the house and the price, we will use the listing_summary database.\n",
    "\n",
    "To retrieve the reservation number we will use the reviews_summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### working listing_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get important feature\n",
    "get_features = [\"id\", \"cancellation_policy\", \"longitude\", \"amenities\",\"requires_license\",\"instant_bookable\",\n",
    "                \"guests_included\",\"latitude\", \"extra_people\",\"require_guest_phone_verification\",\n",
    "               \"bathrooms\",\"bedrooms\",\"beds\", \"price\", \"bed_type\",\"accommodates\",\"host_total_listings_count\",\"host_has_profile_pic\",\n",
    "               \"host_identity_verified\", \"is_location_exact\",\"property_type\",\"host_is_superhost\",\"room_type\",\"minimum_nights\"]\n",
    "dataset_listings = listing_summary[get_features].copy()\n",
    "print(dataset_listings.dtypes)\n",
    "dataset_listings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct data\n",
    "### Derived Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following data is still in object form :\n",
    "- cancellation_policy, amenities, requires_license\n",
    "- instant_bookable, extra_people, require_guest_phone_verification\n",
    "- price, bed_type, host_has_profile_pic, host_has_profile_pic\n",
    "- host_identity_verified, is_location_exact, property_type\n",
    "- host_is_superhost, room_type\n",
    "\n",
    "so we're going to see how we can turn them into digital data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_change = [\"cancellation_policy\", \"amenities\", \"requires_license\",\n",
    "\"instant_bookable\", \"extra_people\", \"require_guest_phone_verification\", \n",
    "\"bed_type\", \"host_has_profile_pic\", \"price\", \"host_has_profile_pic\",\n",
    "\"host_identity_verified\", \"is_location_exact\", \"property_type\",\n",
    "\"host_is_superhost\", \"room_type\"]\n",
    "# data boolean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to change the boolean data contained in data change to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_listings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a62614edb65d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mboolean_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdataset_listings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_listings\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject2bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_listings' is not defined"
     ]
    }
   ],
   "source": [
    "def object2bool(x):\n",
    "    if x==\"t\" or x==\"T\":\n",
    "        return 1.0\n",
    "    elif x==\"f\" or x==\"F\":\n",
    "        return 0.0\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "boolean_features = [\"require_guest_phone_verification\",\"host_is_superhost\",\"host_has_profile_pic\",\n",
    "                    \"host_identity_verified\",\"is_location_exact\",\"requires_license\",\"instant_bookable\"]\n",
    "\n",
    "\n",
    "for x in boolean_features:\n",
    "    dataset_listings[x] = dataset_listings[x].map(object2bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in boolean_features:\n",
    "    data_change.remove(x)\n",
    "\n",
    "data_change.remove(\"host_has_profile_pic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us take care of amenities which represents the list of goods proposed by the host in his reservation \n",
    "\n",
    "as seen above the list has a certain value which is generally found in all the host proposals, the rarer a property is, the more \"general\" properties are found in the list so we can quantify this feature by the number of properties proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now focus on values and extra_people which are string values that can be changed to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean $ sign\n",
    "def clean_price(x):\n",
    "    if ',' in x:\n",
    "        return float(x.replace(\",\", \"\").replace(\"$\",\"\"))\n",
    "        \n",
    "    else:\n",
    "        return float(x.replace(\"$\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_listings.extra_people = dataset_listings.extra_people.map(clean_price)\n",
    "dataset_listings.price = dataset_listings.price.map(clean_price)\n",
    "data_change.remove(\"extra_people\")\n",
    "data_change.remove(\"price\")\n",
    "\n",
    "red_square = dict(markerfacecolor='r', markeredgecolor='r', marker='.')\n",
    "dataset_listings['price'].plot(kind='box', xlim=(0, 1000), vert=False, flierprops=red_square, figsize=(16,2));\n",
    "dataset_listings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is too many outleurs in this features, we will take only price below 120 dollars and we're going to remove reservations that are under 20 dollars , which makes more sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_listings.drop(dataset_listings[ (dataset_listings.price > 120) | (dataset_listings.price < 20) ].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_square = dict(markerfacecolor='r', markeredgecolor='r', marker='.')\n",
    "dataset_listings['price'].plot(kind='box', xlim=(0, 200), vert=False, flierprops=red_square, figsize=(16,2));\n",
    "dataset_listings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now focus on data with more than 2 values, \n",
    "if the number of possibilities is not too large, we will change. \n",
    "\n",
    "Them in a matrix form that we will add to the base.\n",
    "Otherwise we will remove them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data_change:\n",
    "    print(\"feature {} has value : {}\\n\\n\".format(x,dataset_listings[x].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_col = ['bathrooms', 'bedrooms', 'beds',\n",
    "            'host_total_listings_count', 'host_has_profile_pic',\n",
    "           'host_identity_verified', 'host_is_superhost']\n",
    "# Add the median to the feature with Nan\n",
    "for x in null_col:\n",
    "    med = dataset_listings[x].median()\n",
    "    dataset_listings[x] = dataset_listings[x].fillna(med)\n",
    "print_nan_database(dataset_listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Counter()\n",
    "dataset_listings['amenities'].str.strip('{}')\\\n",
    "               .str.replace('\"', '')\\\n",
    "               .str.lstrip('\\\"')\\\n",
    "               .str.rstrip('\\\"')\\\n",
    "               .str.split(',')\\\n",
    "               .apply(results.update)\n",
    "results.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Counter()\n",
    "dataset_listings['amenities'].str.strip('{}')\\\n",
    "               .str.replace('\"', '')\\\n",
    "               .str.lstrip('\\\"')\\\n",
    "               .str.rstrip('\\\"')\\\n",
    "               .str.split(',')\\\n",
    "               .apply(results.update)\n",
    "results.keys()\n",
    "for x in results.keys():\n",
    "    dataset_listings[x] = 0\n",
    "\n",
    "salut = dataset_listings['amenities'].str.strip('{}')\\\n",
    "               .str.replace('\"', '')\\\n",
    "               .str.lstrip('\\\"')\\\n",
    "               .str.rstrip('\\\"')\\\n",
    "               .str.split(',')\n",
    "index = 0\n",
    "for row in salut:\n",
    "    for x in row:\n",
    "        dataset_listings[x][index] = 1\n",
    "    index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_listings.drop('amenities', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "property_type contains too many values to be categorized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_listings.drop(\"property_type\", axis = 1)\n",
    "dataset_listings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_change.remove('amenities')\n",
    "for x in data_change:\n",
    "    value = dataset_listings[[x]]\n",
    "    value.room_type = pd.Categorical(value[x])\n",
    "    del dataset_listings[x]\n",
    "    dummies = pd.get_dummies(value, prefix = x)\n",
    "    dataset_listings = pd.concat([dataset_listings, dummies], axis = 1)\n",
    "\n",
    "dataset_listings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the longitude and latitude of the reservation to know the distance to the center of berlin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_mid(lat, lon):\n",
    "    berlin_centre = (52.5027778, 13.404166666666667)\n",
    "    accommodation = (lat, lon)\n",
    "    return great_circle(berlin_centre, accommodation).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_listings['distance'] = dataset_listings.apply(lambda x: distance_to_mid(x.latitude, x.longitude), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_listings = dataset_listings.drop(['longitude', 'latitude', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reformatted Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to cut dataset_listings in 2 pieces to have our X data which are the input data and our Y data which are our output data (the price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_Y=dataset_listings.price\n",
    "data_X=dataset_listings.drop(['price'], axis = 1)\n",
    "X=np.array(data_X)\n",
    "y=np.array(data_Y)\n",
    "#y = y.reshape(-1,1)\n",
    "#scaler.fit(y)\n",
    "#y = scaler.transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "###  Modeling Technique\n",
    "\n",
    "we decided to use svm support vector machine for our project, \n",
    "the technique used is LinearSVR, it allows to learn on large datasets (more than 10 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Training classifiers\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "\n",
    "gpr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "scores = cross_val_score(gpr, X, y, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "total=0\n",
    "i=0\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    regr = MLPRegressor(random_state=1, max_iter=500)\n",
    "    regr.fit(X_train, y_train)\n",
    "    pred=regr.predict(X_test)\n",
    "    diff=pred-y_test\n",
    "    mean = np.mean(diff)\n",
    "    print(\"average error for kfold number \" + str(i) + \": \" + str(mean))\n",
    "    total += mean\n",
    "    i+=1\n",
    "    test555 = mean_squared_error(y_test, pred)\n",
    "    print(\"RMSE : {}\\n\\n\".format(test555))\n",
    "    \n",
    "    \n",
    "print(\"average error :\" + str(total / 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our average error is -5.42€, which is respectable but we can still see a big difference between our prediction and the truth despite the fact that we have removed apartments that cost more than 120€.\n",
    "\n",
    "This is explainable because the price does not only depend on the data we used (geography, characteristics...), for example an apartment with a beautiful decoration will be necessarily more expensive than a simple apartment without decoration. There is too much non-quantifiable data to take into account so our system is correct for a normal apartment and still gives us an idea of the price, it is up to the user to see if he wants to put more or less expensive compared to the non-quantifiable data that we have not taken into account.\n",
    "\n",
    "Moreover this application can be useful for a client, in fact, for a research made, the client can have a first idea of the price he will have to put in the rental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the RMSE is between 296.87 et 458.67\n",
    "and the average error ocile entre -7.5 et 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model doesn't seem to be converging, and average error is in any case negative we have a model that predicts results below the test values. we are probably in a case of underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we obtained can be used to get an evaluation of the price of his property when you start on airbnb.\n",
    "but also with the average of comments per month over the year you can rent your property in periods that are more often requested such as July and September. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = 5\n",
    "requires_license = 1\n",
    "instant_bookable = 1\n",
    "guests_included = 1\n",
    "extra_people = 10\n",
    "require_guest_phone_verification = 0\n",
    "bathrooms = 1\n",
    "bedrooms = 2\n",
    "beds = 4\n",
    "accomodates = 3\n",
    "host_total_listings_count = 4\n",
    "host_has_profile_pic  = 1\n",
    "host_identity_verified = 1\n",
    "is_location_exact = 1\n",
    "host_is_superhost = 1\n",
    "minimum_nights = 4\n",
    "cancellation = \"cancellation_policy_moderate\"\n",
    "bed_type = \"bed_type_Real Bed\"\n",
    "property_type = \"property_type_Apartment\"\n",
    "room_type = \"room_type_Entire home/apt\"\n",
    "distance =3.52234\n",
    "\n",
    "host = [amenities, requires_license, instant_bookable, guests_included, extra_people,\\\n",
    "    require_guest_phone_verification, bathrooms, bedrooms, beds, accomodates, host_total_listings_count,\\\n",
    "    host_has_profile_pic, host_identity_verified, is_location_exact, host_is_superhost, minimum_nights, \\\n",
    "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0, 0, 0, 0, \\\n",
    "    distance]\n",
    "\n",
    "host = np.array(host)\n",
    "newdf = pd.DataFrame([host], columns = data_X.columns)\n",
    "newdf[cancellation] = 1\n",
    "newdf[bed_type] = 1\n",
    "newdf[property_type] = 1\n",
    "newdf[room_type] = 1\n",
    "pred = np.array(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.predict(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with this price of 62 $ if our client wants to rent his apartment in September and July, he will be able to get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = count_2018_monthly.groupby('date')['reviews_per_month_18'].mean()\n",
    "review_par_month_september = sl.iloc[8]\n",
    "review_par_month_jully = sl.iloc[6]\n",
    "duration_stay_berlin = 3.5\n",
    "revenues_september = regr.predict(pred) * review_par_month_september * duration_stay_berlin\n",
    "print(revenues_september[0])\n",
    "revenues_jully = regr.predict(pred) * review_par_month_jully * duration_stay_berlin\n",
    "print(revenues_jully[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he'll get 685 for the month of September \n",
    "and 605 in the month of July "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dig deeper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the appraised price for his house, \n",
    "but there are other parameters that can influence its performance, such as the number of days rented, which can be influenced by its rating on AirBNB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
